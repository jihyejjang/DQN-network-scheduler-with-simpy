{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reinceforcement learning -scheduling using simpy with dqn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### import "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import simpy\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import random \n",
    "import matplotlib\n",
    "matplotlib.use('TkAgg')\n",
    "import matplotlib.pyplot as plt\n",
    "from prettytable import PrettyTable\n",
    "from collections import deque \n",
    "from itertools import product\n",
    "import math\n",
    "#from DQN import DQN\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.optimizers import Adam \n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dqn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3개의 source, destnation에 대한 min rate array를 state로 한다\n",
    "min rate란 source에서 보내야 하는 filesize(단위?) / deadline까지 남은 시간 (초?) \n",
    " -> mdp는 state에 대한 가치함수를 얻기 때문에 state가 간단해야 함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQN:#모델 선언\n",
    "    def __init__(self): #parameter들의 초기값\n",
    "        #self.gamma = 0.85\n",
    "        self.epsilon = 0.999\n",
    "        self.epsilon_min = 0.01\n",
    "        #self.epsilon_decay = 0.95\n",
    "        self.step = 1\n",
    "        self.tau = 0.125 #?\n",
    "        self.learning_rate = 1\n",
    "        self.memory = deque()\n",
    "        self.model = self.create_model() #현재 state에 대한 model\n",
    "        self.target_model = self.create_model() #next state에 대한 model\n",
    "\n",
    "    # create the neural network to train the q function \n",
    "    def create_model(self): #Q값예측모델. \n",
    "        model = Sequential()\n",
    "        model.add(Dense(24, input_dim= 3, activation= 'relu')) # input dimension : source들 차원\n",
    "        model.add(Dense(48, activation= 'relu'))\n",
    "        model.add(Dense(24, activation= 'relu'))\n",
    "        model.add(Dense(66)) #계산했을 때,(1~10)까지 세 수의 합이 10이 되는 경우의수는 66개. output에 대한 가중치는 매번 update되기 때문에 이에 mapping시키면 된다. \n",
    "        model.compile(loss= 'mean_squared_error', optimizer= Adam(lr= self.learning_rate))\n",
    "        \n",
    "        return model \n",
    "\n",
    "\n",
    "\n",
    "    # Action function to choose the best action given the q-function if not exploring based on epsilon p값에 의한 예측이 아닐때\n",
    "    def choose_action(self, state, allowed_actions): #action을 선택 (parameter로 선택가능한 action이 들어옴)\n",
    "        select = False\n",
    "        if (self.step%10000 == 0):#약 10만번 step에서 10000번마다 epsilon이 감소\n",
    "            self.epsilon = max(self.epsilon_min, pow(self.epsilon,int(self.step/10000 +1)))\n",
    "        print (\"epsilon\", self.epsilon)\n",
    "        self.step+=1\n",
    "        r = np.random.random()\n",
    "        if r < self.epsilon: #p값보다 작은 경우 랜덤한 액션을 취함\n",
    "            print(\"random action\")\n",
    "            return random.choice(allowed_actions),self.step,select\n",
    "        \n",
    "        \n",
    "        print (\"@@action choose@@\" , self.step)\n",
    "        select = True\n",
    "        state = np.array(state).reshape(1,len(state)) #p값보다 큰경우, state 배열 생성\n",
    "        \n",
    "        pred = self.model.predict(state)[0]\n",
    "        #print (\"q\",pred)\n",
    "        \n",
    "        return self.maxQ_action(pred,allowed_actions),self.step,select #Q예측값중 min_rate 이상으로 가장 큰 action을 선택\n",
    "    \n",
    "\n",
    "    def maxQ_action(self,pred,allowed_actions):#allowed action 생성 (min_rate 이상 조합만 남김)\n",
    "        print (\"max q\", np.argmax(pred) )\n",
    "        return allowed_actions[np.argmax(pred)]\n",
    "        \n",
    "        \n",
    "        \n",
    "    # create replay buffer memory to sample randomly #메모리에서 꺼내서 학습할 수 있게 저장, terminal이란 next_state가 없는 경우\n",
    "    def remember(self, state, action, reward, next_state,terminal):\n",
    "        self.memory.append([state, action, reward, next_state,terminal])\n",
    "\n",
    "\n",
    "    # build the replay buffer 저장한 것을 버퍼에서 꺼내오는.? 학습단계?\n",
    "    def replay(self,allowed_actions):\n",
    "        \n",
    "        #global mse_loss\n",
    "        mse=[]\n",
    "        batch_size = 32\n",
    "        if len(self.memory) < batch_size: #buffer에 저장된 memory가 buffer의 총 batch_size보다 작다면 return\n",
    "            return \n",
    "        \n",
    "        samples = random.sample(self.memory, batch_size) #메모리에서 배치사이즈만큼 랜덤으로 선택\n",
    "        \n",
    "        \n",
    "        for sample in samples:\n",
    "            \n",
    "            #print (\"sample\" , sample)\n",
    "            \n",
    "            state, action, reward, new_state, terminal = sample # sample 데이터 하나를 꺼내서\n",
    "            \n",
    "            state = np.array(state).reshape(1,len(state)) \n",
    "            \n",
    "            new_state = np.array(new_state).reshape(1,len(new_state))\n",
    "            \n",
    "            target = self.target_model.predict(state) \n",
    "            \n",
    "            action_id = allowed_actions.index(tuple(action)) #63개의 allowed action 중에서 state에 대한 action의 index를 추출\n",
    "\n",
    "            if terminal :\n",
    "                target[0][action_id] = reward\n",
    "            else :\n",
    "                next_pred = self.target_model.predict(new_state)[0] #new state에 대한 target 예측\n",
    "                  \n",
    "                Q_future= max(next_pred) #next state에 대한 predict 값 중 가장 큰 값이 Q값이 됨\n",
    "                \n",
    "                target[0][action_id] = reward + Q_future * self.learning_rate # target의 action_id번째 위치에 다음 Q값이 들어감. 맞춰야 하는 값!!!\n",
    "            \n",
    "            history=self.model.fit(state, target, epochs= 1, verbose= 0) \n",
    "            mse.append(history.history['loss'][0]) # loss 기록\n",
    "            \n",
    "        return min(mse)\n",
    "        \n",
    "        #print(\"Mean_square_error:\"min(mse_loss))\n",
    "        \n",
    "\n",
    "\n",
    "    # update our target network \n",
    "    def train_target(self): #target network를 업데이트\n",
    "        weights = self.model.get_weights()\n",
    "        target_weights = self.target_model.get_weights()\n",
    "        for i in range(len(target_weights)):\n",
    "            target_weights[i] = weights[i] * self.tau + target_weights[i] * (1 - self.tau)#loss함수?\n",
    "            #target_weights[i] = weights[i]\n",
    "        self.target_model.set_weights(target_weights)\n",
    "\n",
    "\n",
    "\n",
    "    # save our model \n",
    "    def save_model(self, fn):\n",
    "        self.model.save(fn)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model은 현재 state에 대한 q값을 예측\n",
    "\n",
    "target_model은 action에 의한 다음 state'에서의 q' 값을 예측\n",
    "\n",
    "현재 q값이란 reward + q' 가 되므로,\n",
    "\n",
    "model은 reward + q' 를 target으로 하는데\n",
    "\n",
    "그렇기 때문에 target_model이 맞춰야 하는 q' 또한 정확하게 학습이 되어야 함\n",
    "\n",
    "train(replay) 과정에서는 model을 state를 넣으면 올바른 target (reware + q')를 산출하도록 학습시키고,\n",
    "\n",
    "weight update 과정에서는 train_model에 학습된 model의 weight를 넣어준다.\n",
    "\n",
    "train_model도 결국은 model과 같은 매커니즘으로 알맞은 q 예측값을 산출해야하기 때문임\n",
    "\n",
    "\n",
    "=> model의 predict값을 확인한 결과, model weight update에는 문제가 없었고 좋지 않은 state로 흘러감에도 불구하고 pred값이 전혀 감소하지 않음 즉, reward function의 문제\n",
    "\n",
    "=> reward function은 현재 \"Active flow\"에 대해 책정하는 것이 핵심이다. 만약 가장 큰 deadline이 2초 이고, deadline이 완료된 flow의 경우 action을 많이 할당할 수록 reward값이 커지기 때문에 결국 만기된 플로우에 더 큰 pacing rate을 할당하도록 설계된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "********Episode start******** 1\n",
      "\n",
      "state [4, 3, 4]\n",
      "action [10, 0, 0]\n",
      "Tsc 1\n",
      "state [0, 5, 13]\n",
      "epsilon 0.999\n",
      "random action\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 3, got 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-f95ac2d7691e>\u001b[0m in \u001b[0;36mepisode\u001b[1;34m(env, DQN, Tsc, Tfu, allowed_actions)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 62\u001b[1;33m                 \u001b[0maction\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mselect\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdqn_agent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchoose_action\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mallowed_actions\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#DQN에 의한 액션선택\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     63\u001b[0m                 \u001b[0mpexp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#epsilon값\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: not enough values to unpack (expected 3, got 2)",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-f95ac2d7691e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    197\u001b[0m \u001b[0mstart\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# 시작 시간 저장\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprocess\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepisode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mDQN\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mTsc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mTfu\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mallowed_actions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m \u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muntil\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;31m#10만 초 동안 가동\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m \u001b[1;31m#결과 저장\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\simpy\\core.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, until)\u001b[0m\n\u001b[0;32m    252\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    253\u001b[0m             \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 254\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    255\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mStopSimulation\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    256\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mexc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m  \u001b[1;31m# == until.value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\simpy\\core.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    204\u001b[0m             \u001b[0mexc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mevent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    205\u001b[0m             \u001b[0mexc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__cause__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mevent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 206\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mexc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    207\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m     def run(\n",
      "\u001b[1;31mValueError\u001b[0m: not enough values to unpack (expected 3, got 2)"
     ]
    }
   ],
   "source": [
    "#보상 함수 : deactive flow가 누적되서 보상을 받는 것을 방지      \n",
    "def reward_function(deadlines,action,value): #value None이면 active flow\n",
    "    #deactive flow를 제외, deadline이 0인 것은 제외\n",
    "    reward = 0\n",
    "    drem_max=np.max(deadlines) #최대 deadline\n",
    "    for dremi in range(len(deadlines)):\n",
    "        #print (\"drem\",deadlines[dremi])\n",
    "        #print (\"value\",value[dremi])\n",
    "        if ((value[dremi] != 1) and (value[dremi] != 0) and (deadlines[dremi] > 0)) : #active flow, 전송중\n",
    "            reward += ((drem_max - deadlines[dremi])*action[dremi])\n",
    "        elif ((value[dremi] != 1) and (value[dremi] != 0)  and (deadlines[dremi] ==0)) : #active flow, deadline 지남\n",
    "            reward -=1\n",
    "    #print (\"reward\",reward)\n",
    "    return reward\n",
    "\n",
    "    \n",
    "def episode(env,DQN,Tsc,Tfu,allowed_actions): #pacing rate가 각 flow에게 할당\n",
    "    global action\n",
    "    global state\n",
    "    global request\n",
    "    global flow_success\n",
    "    global record\n",
    "    \n",
    "    cnt=1 #episode 수\n",
    "    c=0 #scheduling interval의 수\n",
    "   \n",
    "    #episode 시작\n",
    "    \n",
    "    while True: #Simularion time 동안 episode를 반복한다\n",
    "        print (\"--------------------------------------------------\")\n",
    "        print(\"********Episode start********\",cnt)\n",
    "        print (\"\")\n",
    "        \n",
    "        first_action=1 #new action policy -> EDF\n",
    "        \n",
    "        #1개의 에피소드는 모든 filesize가 0이 될때까지 실행\n",
    "        while ((request['filesize'][0]!=0)or(request['filesize'][1]!=0)or(request['filesize'][2]!=0)):#모두 전송이 완료될 때 까지\n",
    "            c+=1\n",
    "            \n",
    "            #state 결정\n",
    "            \n",
    "            state=[0,0,0] #state 초기화\n",
    "            for s in range(len(sources)):#deadline이 0이 아닌 source는 그대로\n",
    "                if (request['value'][s] == 1) : #deactive (deadline =0 , value =1)\n",
    "                    state[s]=0\n",
    "                else: #active, value=none\n",
    "                    if (request['deadline'][s] > 0) : #active (value = None, deadline >0이면 전송중, deadline =0이면 기한 지남)\n",
    "                        state[s]=math.ceil(request['filesize'][s]/request['deadline'][s])\n",
    "                    elif (request['deadline'][s] == 0):# 기한 지남\n",
    "                        state[s]=10 #link capacity 전체 할당\n",
    "            \n",
    "            print (\"state\", state)\n",
    "\n",
    "            #action 결정\n",
    "            \n",
    "            if (first_action==1): #New state-action policy를 EDF방식으로 (가장 deadline이 시급한)     \n",
    "                action=[0,0,0]\n",
    "                index=np.argmin(request['deadline']) #deadline 최소인 source의 index\n",
    "                action[index]=10 #bottleneck capacity\n",
    "                \n",
    "            else: \n",
    "                action,p,select=dqn_agent.choose_action(state,allowed_actions) #DQN에 의한 액션선택\n",
    "                pexp.append(p) #epsilon값\n",
    "                \n",
    "            print (\"action\", action)\n",
    "                \n",
    "            #Scheduling interval 시작\n",
    "            print (\"Tsc\" , c)\n",
    "            \n",
    "            for i in range(Tsc): \n",
    "                for s in range(len(sources)): #각 source에 대해 \n",
    "                    \n",
    "                    #filesize와 deadline 감소\n",
    "                    \n",
    "                    request['filesize'][s]=max([request['filesize'][s]-int(action[s]),0]) #filesize는 음수 X\n",
    "                    \n",
    "                    if (request['value'][s]==None):\n",
    "                        request['deadline'][s]= request['deadline'][s]-1 #deadline는 음수 가능, active flow에대해서만 감소\n",
    "                    \n",
    "                    # Active, Deactive flow 검사\n",
    "                    \n",
    "                    if ((request['filesize'][s]==0) and (request['value'][s]==None)): #아직 완료되지 않았던 flow가 전송이 완료되면?\n",
    "                        \n",
    "                        if (request['deadline'][s]>=0): #기간 안에 전송되면? 남아있는 시간이 양수, 또는 0 (시간이 0에 딱 맞게 전송 되는 경우도 있음..)\n",
    "                            request['value'][s]=1 #value를 1로 변경\n",
    "                            flow_success.append(1)\n",
    "                            #print (\"s{}의 전송이 deadline 안에 완료됨\".format(s))\n",
    "                            \n",
    "                        else: #기간안에 전송된게 아니라면(value초기값은 None)\n",
    "                            request['value'][s]=0\n",
    "                            flow_success.append(0)\n",
    "                            #print (\"s{}의 전송이 deadline을 지나 완료됨\".format(s))\n",
    "                            \n",
    "                yield env.timeout(Tfu)# Tfu(1초)마다 위 과정 실행\n",
    "            \n",
    "            \n",
    "            \n",
    "            #모든 전송이 완료된 후 next_state는 고려할 필요 없음: terminal=True로 하여 target에 reward를 할당\n",
    "            \n",
    "            if ((request['filesize'][0]==0)and(request['filesize'][1]==0)and(request['filesize'][2]==0)):\n",
    "                terminal = True\n",
    "            else : \n",
    "                terminal = False\n",
    "            \n",
    "            #Next state 결정\n",
    "            \n",
    "            next_state=[0,0,0]\n",
    "            for s in range(len(sources)):\n",
    "                if (request['value'][s] == 1) : \n",
    "                    next_state[s]=0\n",
    "                else: #active, value=none\n",
    "                    if (request['deadline'][s] > 0) : \n",
    "                        next_state[s]=math.ceil(request['filesize'][s]/request['deadline'][s])\n",
    "                    elif (request['deadline'][s] == 0):\n",
    "                        next_state[s]=10 #link capacity\n",
    "\n",
    "            #print(\"next_state\" , next_state)\n",
    "                        \n",
    "            reward = reward_function((request['deadline']),action,request['value'])\n",
    "            cur_state = state \n",
    "            action = action\n",
    "            new_state = next_state \n",
    "            reward = reward\n",
    "            terminal = terminal\n",
    "            \n",
    "            if (first_action==0): # 첫번쨰 선택 액션이 아닌경우에만 학습\n",
    "                dqn_agent.remember(cur_state, action, reward, new_state,terminal) #새로운 state로 설정해주고 기존state저장\n",
    "                mse_loss.append(dqn_agent.replay(allowed_actions))#학습, loss 저장\n",
    "                dqn_agent.train_target()\n",
    "                record.append([cur_state, action, reward, new_state , select]) #select는 action을 random에 의해 선택했는지 dqn에 의해 선택했는지 여부\n",
    "            \n",
    "            first_action=0 \n",
    "\n",
    "        for i in range(len(sources)):\n",
    "            if (request['value'][i]==1):\n",
    "                print (\"source {} 전송완료\".format(i))\n",
    "            else:\n",
    "                print (\"source {} deadine 충족하지 못함\".format(i))\n",
    "        \n",
    "        print(\"모두 전송 완료\")\n",
    "        \n",
    "        #다음 episode에 simulation할 flow생성\n",
    "\n",
    "        filesize=[random.randrange(10,50)for source in range(len(sources))] \n",
    "        deadline=[int(filesize[source]/3) for source in range(len(sources))] #sum_rmin이  9\n",
    "        request = {\n",
    "            'sources' : sources,\n",
    "            'destinations' : destinations, \n",
    "            'filesize' : filesize, #단위는 Gbps\n",
    "            'deadline' : deadline,\n",
    "            'value' : [None for source in sources] #아직 전송되지 않았으면 None, 제시간에 전송되었으면 1, 제시간에 전송되지 않았으면 0\n",
    "        }\n",
    "\n",
    "        state=[0,0,0]#초기 state\n",
    "        action=[0,0,0]#초기 action ->고칠것\n",
    "        print (\"********episode end********\")\n",
    "        print(\"--------------------------------------------------\")\n",
    "        cnt+=1\n",
    "    \n",
    "    \n",
    "    \n",
    "# main함수\n",
    "\n",
    "env = simpy.Environment()\n",
    "dqn_agent = DQN()\n",
    "\n",
    "#npz\n",
    "mse_loss=[] #episode의 진행에 따른 mse_loss의 변화율 graph\n",
    "flow_success=[] #episode의 진행에 따른 flow_success rate\n",
    "pexp=[] #action choice 진행에 따른 pexp 변화\n",
    "record = []\n",
    "\n",
    "state=[0,0,0]#초기 state\n",
    "action=[0,0,0]#초기 action ->고칠것\n",
    "Tsc=3 #scheduling interval을 구성하는 flow update interval의 수\n",
    "Tfu=1 #flow update interval의 시간단위(0.1초로 가정)\n",
    "sources = ['s0', 's1', 's2']\n",
    "destinations = ['d0', 'd1', 'd2']\n",
    "filesize=[random.randrange(10,50) for source in range(len(sources))] #단위 Gb\n",
    "deadline=[int(filesize[source]/3) for source in range(len(sources))] #sum_rmin이  9Gbps, 각각 3\n",
    "request = {\n",
    "    'sources' : sources,\n",
    "    'destinations' : destinations, \n",
    "    'filesize' : filesize, #단위는 Mbps\n",
    "    'deadline' : deadline,\n",
    "    'value' : [None for source in sources] #아직 전송되지 않았으면 None, 제시간에 전송되었으면 1, 제시간에 전송되지 않았으면 0\n",
    "}\n",
    "\n",
    "A=list(range(11))\n",
    "B=list(range(11))\n",
    "C=list(range(11)) \n",
    "allowed_actions=[] #합이 10이 되는 0~10까지의 수 조합\n",
    "for i in list(product(*(A,B,C))):\n",
    "    if sum(list(i))==10:\n",
    "        allowed_actions.append(i) #d는 66개의 조합\n",
    "        \n",
    "start = time.time()  # 시작 시간 저장\n",
    "env.process(episode(env,DQN,Tsc,Tfu,allowed_actions))\n",
    "env.run(until=100000)#10만 초 동안 가동\n",
    "\n",
    "#결과 저장\n",
    "np.savez('simulation history 1029_notebook',loss = mse_loss, success = flow_success, p = pexp, record = record )\n",
    "dqn_agent.save_model(\"dqn_policy.h5\")\n",
    "\n",
    "print(\"종료\")\n",
    "print(\"time :\", time.time() - start)  # 현재시각 - 시작시간 = 실행 시간\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " ...]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flow_success"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(flow_success)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 0 1 0 0 1 0 0 1 1 0 1 0 0]\n",
      "0.4\n",
      "[1 0 0 1 0 0 1 0 1 1 0 0 1 0 0]\n",
      "0.4\n",
      "[1 0 0 1 0 0 1 1 0 1 1 0 1 0 0]\n",
      "0.4666666666666667\n",
      "[1 1 0 1 0 0 1 1 0 1 1 0 1 0 0]\n",
      "0.5333333333333333\n",
      "[1 0 0 1 0 0 1 0 0 1 0 0 1 0 0]\n",
      "0.3333333333333333\n",
      "[1 1 0 1 0 0 1 1 0 1 1 0 1 0 0]\n",
      "0.5333333333333333\n",
      "[1 1 0 1 1 0 1 0 1 1 0 0 1 1 0]\n",
      "0.6\n",
      "[1 0 0 1 0 0 1 0 0 1 1 0 1 0 0]\n",
      "0.4\n",
      "[1 0 0 1 0 0 1 0 0 1 0 0 1 0 0]\n",
      "0.3333333333333333\n",
      "[1 1 0 1 0 0 1 0 0 1 0 0 1 0 0]\n",
      "0.4\n",
      "[1 0 0 1 0 0 1 0 0 1 1 0 1 1 0]\n",
      "0.4666666666666667\n",
      "[1 0 0 1 0 0 1 0 1 1 0 0 1 0 0]\n",
      "0.4\n",
      "[1 0 0 1 0 0 1 0 0 1 0 0 1 0 0]\n",
      "0.3333333333333333\n",
      "[1 0 1 1 0 0 1 1 0 1 0 0 1 1 0]\n",
      "0.5333333333333333\n",
      "[1 1 0 1 0 0 1 1 0 1 0 0 1 1 0]\n",
      "0.5333333333333333\n",
      "[1 0 0 1 0 0 1 0 0 1 1 0 1 0 0]\n",
      "0.4\n",
      "[1 0 0 1 0 0 1 1 0 1 0 0 1 0 0]\n",
      "0.4\n",
      "[1 0 0 1 0 0 1 0 0 1 1 0 1 0 0]\n",
      "0.4\n",
      "[1 1 0 1 0 0 1 0 0 1 1 0 1 0 0]\n",
      "0.4666666666666667\n",
      "[1 0 0 1 0 0 1 0 0 1 0 0 1 1 0]\n",
      "0.4\n",
      "[1 0 0 1 0 0 1 0 0 1 0 0 1 0 0]\n",
      "0.3333333333333333\n",
      "[1 1 0 1 1 0 1 1 0 1 1 0 1 0 0]\n",
      "0.6\n",
      "[1 0 0 1 0 0 1 0 0 1 0 0 1 0 0]\n",
      "0.3333333333333333\n",
      "[1 0 0 1 1 0 1 1 0 1 0 0 1 1 0]\n",
      "0.5333333333333333\n",
      "[1 0 0 1 1 0 1 1 0 1 0 0 1 0 0]\n",
      "0.4666666666666667\n",
      "[1 0 1 1 1 0 1 0 0 1 1 0 1 0 1]\n",
      "0.6\n",
      "[1 0 0 1 0 0 1 0 0 1 0 0 1 1 0]\n",
      "0.4\n",
      "[1 0 1 1 1 0 1 0 0 1 0 0 1 0 0]\n",
      "0.4666666666666667\n",
      "[1 1 0 1 1 0 1 0 0 1 1 0 1 0 0]\n",
      "0.5333333333333333\n",
      "[1 1 0 1 1 0 1 0 0 1 1 0 1 0 0]\n",
      "0.5333333333333333\n",
      "[1 1 0 1 0 0 1 0 0 1 1 0 1 0 0]\n",
      "0.4666666666666667\n",
      "[1 0 0 1 0 0 1 0 0 1 1 0 1 1 0]\n",
      "0.4666666666666667\n",
      "[1 0 0 1 1 0 1 0 0 1 1 0 1 1 0]\n",
      "0.5333333333333333\n",
      "[1 0 0 1 1 0 1 1 0 1 0 0 1 0 0]\n",
      "0.4666666666666667\n",
      "[1 1 0 1 1 0 1 0 0 1 0 0 1 1 0]\n",
      "0.5333333333333333\n",
      "[1 1 0 1 1 0 1 0 0 1 1 0 1 1 0]\n",
      "0.6\n",
      "[1 0 0 1 0 0 1 1 0 1 1 0 1 1 0]\n",
      "0.5333333333333333\n",
      "[1 1 0 1 0 0 1 0 0 1 0 0 1 1 0]\n",
      "0.4666666666666667\n",
      "[1 0 0 1 0 0 1 1 0 1 0 0 1 0 0]\n",
      "0.4\n",
      "[1 0 0 1 0 0 1 0 0 1 0 0 1 0 0]\n",
      "0.3333333333333333\n",
      "[1 1 0 1 0 0 1 0 0 1 0 0 1 1 0]\n",
      "0.4666666666666667\n",
      "[1 0 0 1 0 0 1 0 0 1 1 0 1 0 1]\n",
      "0.4666666666666667\n",
      "[1 1 0 1 0 0 1 0 0 1 1 0 1 1 0]\n",
      "0.5333333333333333\n",
      "[1 1 0 1 0 0 1 1 0 1 0 0 1 1 0]\n",
      "0.5333333333333333\n",
      "[1 1 0 1 0 0 1 1 0 1 0 0 1 1 0]\n",
      "0.5333333333333333\n",
      "[1 0 0 1 0 0 1 0 0 1 0 0 1 1 0]\n",
      "0.4\n",
      "[1 0 0 1 0 0 1 0 0 1 0 0 1 1 0]\n",
      "0.4\n",
      "[1 0 0 1 0 0 1 1 0 1 0 0 1 0 0]\n",
      "0.4\n",
      "[1 1 0 1 0 0 1 0 0 1 1 0 1 0 0]\n",
      "0.4666666666666667\n",
      "[1 1 0 1 1 0 1 0 0 1 1 0 1 0 0]\n",
      "0.5333333333333333\n",
      "[1 0 0 1 1 0 1 1 0 1 0 0 1 1 0]\n",
      "0.5333333333333333\n",
      "[1 1 0 1 1 0 1 0 0 1 0 0 1 0 0]\n",
      "0.4666666666666667\n",
      "[1 0 0 1 0 0 1 1 0 1 0 0 1 0 0]\n",
      "0.4\n",
      "[1 0 0 1 1 0 1 0 0 1 1 0 1 0 0]\n",
      "0.4666666666666667\n",
      "[1 0 0 1 0 0 1 0 0 1 1 0 1 0 0]\n",
      "0.4\n",
      "[1 0 0 1 1 0 1 0 0 1 0 0 1 0 0]\n",
      "0.4\n",
      "[1 0 0 1 0 0 1 0 0 1 1 0 1 0 1]\n",
      "0.4666666666666667\n",
      "[1 0 0 1 0 0 1 0 0 1 0 0 1 1 0]\n",
      "0.4\n",
      "[1 1 0 1 1 0 1 0 0 1 0 0 1 1 0]\n",
      "0.5333333333333333\n",
      "[1 0 0 1 0 0 1 1 0 1 0 0 1 1 0]\n",
      "0.4666666666666667\n",
      "[1 0 0 1 0 0 1 0 0 1 0 0 1 0 0]\n",
      "0.3333333333333333\n",
      "[1 1 0 1 1 0 1 0 0 1 0 0 1 0 0]\n",
      "0.4666666666666667\n",
      "[1 1 0 1 0 0 1 1 0 1 1 0 1 0 0]\n",
      "0.5333333333333333\n",
      "[1 1 0 1 0 0 1 1 0 1 0 0 1 1 0]\n",
      "0.5333333333333333\n",
      "[1 1 0 1 0 0 1 0 0 1 0 0 1 0 0]\n",
      "0.4\n",
      "[1 1 0 1 1 0 1 1 0 1 0 1 1 0 0]\n",
      "0.6\n",
      "[1 1 0 1 0 0 1 1 0 1 0 0 1 1 0]\n",
      "0.5333333333333333\n",
      "[1 1 0 1 0 0 1 1 0 1 0 0 1 1 0]\n",
      "0.5333333333333333\n",
      "[1 0 0 1 1 0 1 0 0 1 0 0 1 1 0]\n",
      "0.4666666666666667\n",
      "[1 1 0 1 1 0 1 1 0 1 0 0 1 1 0]\n",
      "0.6\n",
      "[1 1 0 1 0 0 1 0 0 1 0 0 1 0 1]\n",
      "0.4666666666666667\n",
      "[1 0 0 1 0 1 1 0 0 1 0 0 1 0 0]\n",
      "0.4\n",
      "[1 1 0 1 1 0 1 0 0 1 0 0 1 1 0]\n",
      "0.5333333333333333\n",
      "[1 1 0 1 0 0 1 0 0 1 1 0 1 1 0]\n",
      "0.5333333333333333\n",
      "[1 0 0 1 0 0 1 0 0 1 0 0 1 0 0]\n",
      "0.3333333333333333\n",
      "[1 0 0 1 0 0 1 0 0 1 0 1 1 0 0]\n",
      "0.4\n",
      "[1 0 0 1 1 0 1 0 0 1 1 0 1 1 0]\n",
      "0.5333333333333333\n",
      "[1 0 0 1 1 0 1 0 0 1 0 0 1 1 0]\n",
      "0.4666666666666667\n",
      "[1 0 1 1 0 0 1 0 0 1 0 0 1 0 0]\n",
      "0.4\n",
      "[1 0 0 1 0 1 1 0 0 1 0 0 1 0 0]\n",
      "0.4\n",
      "[1 0 0 1 0 0 1 0 0 1 0 0 1 1 0]\n",
      "0.4\n",
      "[1 0 0 1 0 0 1 1 0 1 0 0 1 0 0]\n",
      "0.4\n",
      "[1 0 0 1 0 0 1 0 0 1 1 0 1 0 0]\n",
      "0.4\n",
      "[1 0 0 1 0 0 1 0 0 1 0 0 1 1 0]\n",
      "0.4\n",
      "[1 1 0 1 0 1 1 0 0 1 0 0 1 0 0]\n",
      "0.4666666666666667\n",
      "[1 0 0 1 0 0 1 0 0 1 0 0 1 0 1]\n",
      "0.4\n",
      "[1 0 0 1 0 0 1 0 0 1 0 0 1 1 0]\n",
      "0.4\n",
      "[1 0 0 1 1 0 1 0 0 1 1 0 1 1 0]\n",
      "0.5333333333333333\n",
      "[1 0 0 1 1 0 1 1 0 1 0 1 1 0 0]\n",
      "0.5333333333333333\n",
      "[1 0 1 1 1 0 1 1 0 1 1 0 1 1 0]\n",
      "0.6666666666666666\n",
      "[1 0 0 1 0 0 1 0 0 1 0 0 1 1 0]\n",
      "0.4\n",
      "[1 0 0 1 0 0 1 0 0 1 1 0 1 1 0]\n",
      "0.4666666666666667\n",
      "[1 1 0 1 0 0 1 0 0 1 0 0 1 0 0]\n",
      "0.4\n",
      "[1 0 0 1 1 0 1 0 0 1 0 0 1 1 0]\n",
      "0.4666666666666667\n",
      "[1 1 0 1 0 0 1 1 0 1 0 0 1 0 0]\n",
      "0.4666666666666667\n",
      "[1 0 0 1 1 0 1 1 0 1 1 0 1 0 1]\n",
      "0.6\n",
      "[1 0 0 1 1 0 1 0 0 1 0 0 1 1 0]\n",
      "0.4666666666666667\n",
      "[1 0 0 1 0 0 1 1 0 1 0 0 1 1 0]\n",
      "0.4666666666666667\n",
      "[1 0 0 1 0 0 1 0 0 1 1 0 1 0 0]\n",
      "0.4\n",
      "[1 0 0 1 0 1 1 0 0 1 1 0 1 0 0]\n",
      "0.4666666666666667\n",
      "[1 1 0 1 0 0 1 0 0 1 0 0 1 1 0]\n",
      "0.4666666666666667\n",
      "[1 0 0 1 0 0 1 0 0 1 1 0 1 1 0]\n",
      "0.4666666666666667\n",
      "[1 0 0 1 1 0 1 0 0 1 1 0 1 0 0]\n",
      "0.4666666666666667\n",
      "[1 0 0 1 0 0 1 1 0 1 0 0 1 1 0]\n",
      "0.4666666666666667\n"
     ]
    }
   ],
   "source": [
    "rate=[]\n",
    "flow_success=np.array(flow_success)\n",
    "for i in range(int(len(flow_success)/15)):#200개당평균\n",
    "    print(flow_success[15*i:15*(i+1)])\n",
    "    rate.append(np.mean(flow_success[15*i:15*(i+1)]))\n",
    "    print(np.mean(flow_success[15*i:15*(i+1)]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# x = mse_loss\n",
    "\n",
    "# plt.plot(x)\n",
    "# plt.show()\n",
    "\n",
    "#flow_success_rate=\n",
    "x2 = rate\n",
    "\n",
    "plt.plot(x2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(mse_loss)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
